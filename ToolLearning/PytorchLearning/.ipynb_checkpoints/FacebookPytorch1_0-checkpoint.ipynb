{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Facebook Pytorch 1.0 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?\n",
    "**PyTorch的组成部分：**\n",
    "1. automatic differentiation engine\n",
    "2. Ndarray library with GPU support\n",
    "3. Distributed training\n",
    "4. Production-ready C++ runtime\n",
    "5. gradient based optimization package\n",
    "6. Utilities(data loading,etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ndarray library\n",
    "Pytorch被称为神经网络的numpy，为什么呢？因为`np.ndarry` <-> `torch.Tensor`中的操作非常相似，加上GPU，所以运算非常快，下面我们比较一下：\n",
    "\n",
    "* 首先是numpy 代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 turn:  25902431.879741177\n",
      "1 turn:  19667915.881960966\n",
      "2 turn:  15703056.330939017\n",
      "3 turn:  12327716.761904921\n",
      "4 turn:  9261643.786908623\n",
      "5 turn:  6650974.979294437\n",
      "6 turn:  4634447.263955887\n",
      "7 turn:  3192417.3091512616\n",
      "8 turn:  2215607.1908576544\n",
      "9 turn:  1570944.481600485\n",
      "10 turn:  1145688.8724153633\n",
      "11 turn:  862917.4575967597\n",
      "12 turn:  669830.348605209\n",
      "13 turn:  533807.5029864854\n",
      "14 turn:  434891.61297826376\n",
      "15 turn:  360650.2440819749\n",
      "16 turn:  303279.8470286433\n",
      "17 turn:  257781.675638947\n",
      "18 turn:  220997.61671311493\n",
      "19 turn:  190788.10689599218\n",
      "20 turn:  165636.85301751236\n",
      "21 turn:  144447.24898729956\n",
      "22 turn:  126464.36986866029\n",
      "23 turn:  111101.4644300804\n",
      "24 turn:  97903.51607467321\n",
      "25 turn:  86501.50336650021\n",
      "26 turn:  76614.88797254513\n",
      "27 turn:  68004.53541816722\n",
      "28 turn:  60481.781052643564\n",
      "29 turn:  53888.58197762249\n",
      "30 turn:  48100.6526167174\n",
      "31 turn:  43004.21008457731\n",
      "32 turn:  38502.26470520457\n",
      "33 turn:  34520.42071436035\n",
      "34 turn:  30992.228937691594\n",
      "35 turn:  27861.528989045695\n",
      "36 turn:  25080.636169774876\n",
      "37 turn:  22607.38394269219\n",
      "38 turn:  20406.568710251217\n",
      "39 turn:  18440.344891200773\n",
      "40 turn:  16683.70361585092\n",
      "41 turn:  15110.01156784856\n",
      "42 turn:  13699.98752295794\n",
      "43 turn:  12433.35268130574\n",
      "44 turn:  11293.382872256041\n",
      "45 turn:  10266.112457910207\n",
      "46 turn:  9338.973879103713\n",
      "47 turn:  8501.72568331862\n",
      "48 turn:  7745.065862976546\n",
      "49 turn:  7060.626866854718\n",
      "50 turn:  6441.55970336961\n",
      "51 turn:  5880.398153990335\n",
      "52 turn:  5371.174959784472\n",
      "53 turn:  4908.875786508029\n",
      "54 turn:  4488.900446187956\n",
      "55 turn:  4106.900699463187\n",
      "56 turn:  3759.2504637554384\n",
      "57 turn:  3442.861078294462\n",
      "58 turn:  3154.5467729098827\n",
      "59 turn:  2891.7460316597308\n",
      "60 turn:  2651.987245699856\n",
      "61 turn:  2433.1756109341422\n",
      "62 turn:  2233.3990010470934\n",
      "63 turn:  2050.84325768622\n",
      "64 turn:  1883.9450616784104\n",
      "65 turn:  1731.5018562782375\n",
      "66 turn:  1591.9545981923427\n",
      "67 turn:  1464.280987651638\n",
      "68 turn:  1347.3376683203628\n",
      "69 turn:  1240.1466345046583\n",
      "70 turn:  1141.9615494433633\n",
      "71 turn:  1051.9052402292507\n",
      "72 turn:  969.2431431058246\n",
      "73 turn:  893.3578663995013\n",
      "74 turn:  823.6774979340476\n",
      "75 turn:  759.6874849061501\n",
      "76 turn:  700.9437586249365\n",
      "77 turn:  646.9065655999876\n",
      "78 turn:  597.2102554244776\n",
      "79 turn:  551.4949372286114\n",
      "80 turn:  509.43816786447627\n",
      "81 turn:  470.72208427066596\n",
      "82 turn:  435.08496201494575\n",
      "83 turn:  402.26805141435295\n",
      "84 turn:  372.0138251592045\n",
      "85 turn:  344.124383895698\n",
      "86 turn:  318.41523612349715\n",
      "87 turn:  294.71431845797423\n",
      "88 turn:  272.8390813070329\n",
      "89 turn:  252.65103823189216\n",
      "90 turn:  234.01506179948947\n",
      "91 turn:  216.8087551164233\n",
      "92 turn:  200.9244261267948\n",
      "93 turn:  186.25221741727066\n",
      "94 turn:  172.68760621635136\n",
      "95 turn:  160.15031280140974\n",
      "96 turn:  148.56054005894765\n",
      "97 turn:  137.8372175992073\n",
      "98 turn:  127.91991325859985\n",
      "99 turn:  118.75138800348756\n",
      "100 turn:  110.26487474124909\n",
      "101 turn:  102.41039768764666\n",
      "102 turn:  95.1333265255108\n",
      "103 turn:  88.39346526737651\n",
      "104 turn:  82.15044613473059\n",
      "105 turn:  76.36425084544203\n",
      "106 turn:  70.99933464423403\n",
      "107 turn:  66.02571442281021\n",
      "108 turn:  61.414244476108024\n",
      "109 turn:  57.13907851868351\n",
      "110 turn:  53.171494445953726\n",
      "111 turn:  49.488627371120366\n",
      "112 turn:  46.069920157606646\n",
      "113 turn:  42.89515486747504\n",
      "114 turn:  39.94756853571388\n",
      "115 turn:  37.20978180900774\n",
      "116 turn:  34.66745046500081\n",
      "117 turn:  32.30360732980086\n",
      "118 turn:  30.107300971386387\n",
      "119 turn:  28.065622663412583\n",
      "120 turn:  26.167292335773162\n",
      "121 turn:  24.402515659890298\n",
      "122 turn:  22.762056006581915\n",
      "123 turn:  21.23401209293017\n",
      "124 turn:  19.812268254217525\n",
      "125 turn:  18.48901937523243\n",
      "126 turn:  17.257567573709732\n",
      "127 turn:  16.11117562819771\n",
      "128 turn:  15.043502591390881\n",
      "129 turn:  14.04868752991913\n",
      "130 turn:  13.12194477495441\n",
      "131 turn:  12.258587995268186\n",
      "132 turn:  11.453983009205043\n",
      "133 turn:  10.70432784966357\n",
      "134 turn:  10.005809973393832\n",
      "135 turn:  9.353662130801748\n",
      "136 turn:  8.745497939650331\n",
      "137 turn:  8.178370554828074\n",
      "138 turn:  7.649167636163728\n",
      "139 turn:  7.155592945780702\n",
      "140 turn:  6.694686495495442\n",
      "141 turn:  6.2644647309643915\n",
      "142 turn:  5.862864648807858\n",
      "143 turn:  5.4878020372902085\n",
      "144 turn:  5.137555907235001\n",
      "145 turn:  4.810568565660715\n",
      "146 turn:  4.505044509274221\n",
      "147 turn:  4.219514133614725\n",
      "148 turn:  3.9525850952351815\n",
      "149 turn:  3.703065383916044\n",
      "150 turn:  3.4699032882551144\n",
      "151 turn:  3.2518666689491784\n",
      "152 turn:  3.0479213403836214\n",
      "153 turn:  2.8571417611194967\n",
      "154 turn:  2.678658947873913\n",
      "155 turn:  2.511679391008706\n",
      "156 turn:  2.35553283532696\n",
      "157 turn:  2.2094521153289444\n",
      "158 turn:  2.0725620396257836\n",
      "159 turn:  1.9444029945137216\n",
      "160 turn:  1.8244079891411593\n",
      "161 turn:  1.7120592528263507\n",
      "162 turn:  1.6069296648150575\n",
      "163 turn:  1.5083395742769032\n",
      "164 turn:  1.4159785010556503\n",
      "165 turn:  1.3294342454714005\n",
      "166 turn:  1.2483428249630504\n",
      "167 turn:  1.172424638579899\n",
      "168 turn:  1.1012019991759614\n",
      "169 turn:  1.034396508908697\n",
      "170 turn:  0.9717564256100037\n",
      "171 turn:  0.9130222221123119\n",
      "172 turn:  0.8579339854299484\n",
      "173 turn:  0.8062727666364026\n",
      "174 turn:  0.757804929223045\n",
      "175 turn:  0.7123153273934077\n",
      "176 turn:  0.6696600888607904\n",
      "177 turn:  0.6296216392646574\n",
      "178 turn:  0.5920163463611552\n",
      "179 turn:  0.5567356518937989\n",
      "180 turn:  0.5236008982530804\n",
      "181 turn:  0.4924854888656713\n",
      "182 turn:  0.4632609879216851\n",
      "183 turn:  0.4358143215374189\n",
      "184 turn:  0.41003601112072674\n",
      "185 turn:  0.38584848386519066\n",
      "186 turn:  0.36310468536678586\n",
      "187 turn:  0.34172984085223\n",
      "188 turn:  0.3216382161887748\n",
      "189 turn:  0.3027583748437487\n",
      "190 turn:  0.28501398821206714\n",
      "191 turn:  0.26833768911200706\n",
      "192 turn:  0.252651804989108\n",
      "193 turn:  0.2379048499075533\n",
      "194 turn:  0.22405022245685866\n",
      "195 turn:  0.21101014050186523\n",
      "196 turn:  0.1987464976312059\n",
      "197 turn:  0.18721193409351317\n",
      "198 turn:  0.17636020155164855\n",
      "199 turn:  0.1661482667851628\n",
      "200 turn:  0.15654018859577365\n",
      "201 turn:  0.14749938520248626\n",
      "202 turn:  0.13900130034181526\n",
      "203 turn:  0.130997223671877\n",
      "204 turn:  0.12345952804044019\n",
      "205 turn:  0.11636412680784693\n",
      "206 turn:  0.10968541619119918\n",
      "207 turn:  0.10339767249091192\n",
      "208 turn:  0.09747951614735645\n",
      "209 turn:  0.0919041294790966\n",
      "210 turn:  0.08665704875606159\n",
      "211 turn:  0.08171259781377452\n",
      "212 turn:  0.07705479249095987\n",
      "213 turn:  0.072667419446792\n",
      "214 turn:  0.06853540389403022\n",
      "215 turn:  0.06464186770082037\n",
      "216 turn:  0.06097237026898573\n",
      "217 turn:  0.05751628843856565\n",
      "218 turn:  0.054259090067460214\n",
      "219 turn:  0.05119076041825609\n",
      "220 turn:  0.04829773859702166\n",
      "221 turn:  0.04556982206811883\n",
      "222 turn:  0.04299844193236374\n",
      "223 turn:  0.04057494224056757\n",
      "224 turn:  0.038290958515066725\n",
      "225 turn:  0.03613783222419072\n",
      "226 turn:  0.034106639194329956\n",
      "227 turn:  0.03219130338800727\n",
      "228 turn:  0.03038517778430556\n",
      "229 turn:  0.028681588807520943\n",
      "230 turn:  0.027074947610945345\n",
      "231 turn:  0.025561666174693944\n",
      "232 turn:  0.024132491931736076\n",
      "233 turn:  0.02278405652966845\n",
      "234 turn:  0.021511990869381888\n",
      "235 turn:  0.020312006192290937\n",
      "236 turn:  0.01918024365458272\n",
      "237 turn:  0.018112754958608757\n",
      "238 turn:  0.017104968884360652\n",
      "239 turn:  0.01615375179708508\n",
      "240 turn:  0.01525632833756257\n",
      "241 turn:  0.014409156008280471\n",
      "242 turn:  0.013609815964507128\n",
      "243 turn:  0.012855567552176672\n",
      "244 turn:  0.0121437109394431\n",
      "245 turn:  0.011471336100578575\n",
      "246 turn:  0.010836611541906033\n",
      "247 turn:  0.010237433991086873\n",
      "248 turn:  0.009672211056378603\n",
      "249 turn:  0.00913836268610371\n",
      "250 turn:  0.008634246914576304\n",
      "251 turn:  0.0081581151190163\n",
      "252 turn:  0.007708590885434447\n",
      "253 turn:  0.00728405749317642\n",
      "254 turn:  0.006883270375649825\n",
      "255 turn:  0.006504794654337492\n",
      "256 turn:  0.006147252968907987\n",
      "257 turn:  0.005809523457590225\n",
      "258 turn:  0.005490500267785075\n",
      "259 turn:  0.005189199255967822\n",
      "260 turn:  0.004904753030793321\n",
      "261 turn:  0.004636016196476907\n",
      "262 turn:  0.004381998131270914\n",
      "263 turn:  0.004142030919839877\n",
      "264 turn:  0.003915342838853349\n",
      "265 turn:  0.0037012529469110577\n",
      "266 turn:  0.003499052256316873\n",
      "267 turn:  0.0033078394183046755\n",
      "268 turn:  0.003127170569051255\n",
      "269 turn:  0.002956496261452622\n",
      "270 turn:  0.002795183142704859\n",
      "271 turn:  0.0026428662551118195\n",
      "272 turn:  0.0024988229153926978\n",
      "273 turn:  0.002362699303174137\n",
      "274 turn:  0.0022340415339139465\n",
      "275 turn:  0.002112449520938235\n",
      "276 turn:  0.0019975684682335204\n",
      "277 turn:  0.0018889930158931282\n",
      "278 turn:  0.0017863044904586722\n",
      "279 turn:  0.0016892336035304524\n",
      "280 turn:  0.0015974867502590402\n",
      "281 turn:  0.0015108069771379213\n",
      "282 turn:  0.001428827545581348\n",
      "283 turn:  0.001351339675457398\n",
      "284 turn:  0.0012780579333945643\n",
      "285 turn:  0.0012088047938374055\n",
      "286 turn:  0.001143335549961839\n",
      "287 turn:  0.0010814067622037936\n",
      "288 turn:  0.0010228646146218786\n",
      "289 turn:  0.0009675192488090246\n",
      "290 turn:  0.000915215143672977\n",
      "291 turn:  0.000865720984770422\n",
      "292 turn:  0.0008189165607682355\n",
      "293 turn:  0.0007746583602369848\n",
      "294 turn:  0.0007328424411083482\n",
      "295 turn:  0.0006932763052105065\n",
      "296 turn:  0.0006558472636059953\n",
      "297 turn:  0.0006204512511477156\n",
      "298 turn:  0.0005869925224476539\n",
      "299 turn:  0.0005553535451659805\n",
      "300 turn:  0.0005254213710987915\n",
      "301 turn:  0.00049710092542193\n",
      "302 turn:  0.0004703223845211501\n",
      "303 turn:  0.00044500188425022826\n",
      "304 turn:  0.0004210385444394743\n",
      "305 turn:  0.0003983756644628934\n",
      "306 turn:  0.0003769444198647775\n",
      "307 turn:  0.0003566779027766775\n",
      "308 turn:  0.0003374935999901309\n",
      "309 turn:  0.00031934659161121377\n",
      "310 turn:  0.0003021825726337542\n",
      "311 turn:  0.0002859585793087375\n",
      "312 turn:  0.00027059769912988\n",
      "313 turn:  0.00025606412736542167\n",
      "314 turn:  0.00024231518892271252\n",
      "315 turn:  0.0002293158913187318\n",
      "316 turn:  0.00021700945501176646\n",
      "317 turn:  0.00020536971441990456\n",
      "318 turn:  0.00019435555108204372\n",
      "319 turn:  0.00018393800368825516\n",
      "320 turn:  0.0001740776594504881\n",
      "321 turn:  0.0001647481466005371\n",
      "322 turn:  0.0001559245861539491\n",
      "323 turn:  0.00014757540529492565\n",
      "324 turn:  0.00013967246192801074\n",
      "325 turn:  0.00013219316662492912\n",
      "326 turn:  0.0001251189475947562\n",
      "327 turn:  0.00011842212435009325\n",
      "328 turn:  0.00011208790975538055\n",
      "329 turn:  0.00010609345644226235\n",
      "330 turn:  0.00010042022278421576\n",
      "331 turn:  9.504989817085725e-05\n",
      "332 turn:  8.99690598654437e-05\n",
      "333 turn:  8.516212790474584e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 turn:  8.061175915059923e-05\n",
      "335 turn:  7.630478851167481e-05\n",
      "336 turn:  7.222998583053305e-05\n",
      "337 turn:  6.837333738253106e-05\n",
      "338 turn:  6.472206563795398e-05\n",
      "339 turn:  6.126706406838408e-05\n",
      "340 turn:  5.799840992027617e-05\n",
      "341 turn:  5.490385132341202e-05\n",
      "342 turn:  5.1974346769910984e-05\n",
      "343 turn:  4.9203306370805166e-05\n",
      "344 turn:  4.657871977932011e-05\n",
      "345 turn:  4.409529028559907e-05\n",
      "346 turn:  4.1745624660792006e-05\n",
      "347 turn:  3.952013064859082e-05\n",
      "348 turn:  3.741356884119265e-05\n",
      "349 turn:  3.542060156858078e-05\n",
      "350 turn:  3.3533779546417576e-05\n",
      "351 turn:  3.174752076868103e-05\n",
      "352 turn:  3.005717396162182e-05\n",
      "353 turn:  2.8456440277215083e-05\n",
      "354 turn:  2.694151207641914e-05\n",
      "355 turn:  2.5507608710717385e-05\n",
      "356 turn:  2.4149800209581932e-05\n",
      "357 turn:  2.2864786125790542e-05\n",
      "358 turn:  2.1648662869251148e-05\n",
      "359 turn:  2.0496921600090074e-05\n",
      "360 turn:  1.940650390396995e-05\n",
      "361 turn:  1.8374549444551858e-05\n",
      "362 turn:  1.7397406651527572e-05\n",
      "363 turn:  1.6472867115506033e-05\n",
      "364 turn:  1.5597395823464107e-05\n",
      "365 turn:  1.4768212929909971e-05\n",
      "366 turn:  1.3983321497920394e-05\n",
      "367 turn:  1.3240439398183686e-05\n",
      "368 turn:  1.2537063793805674e-05\n",
      "369 turn:  1.1871165297909287e-05\n",
      "370 turn:  1.124055623128511e-05\n",
      "371 turn:  1.0643502132343109e-05\n",
      "372 turn:  1.0078544497745544e-05\n",
      "373 turn:  9.54331170901352e-06\n",
      "374 turn:  9.03675209901408e-06\n",
      "375 turn:  8.557081994572229e-06\n",
      "376 turn:  8.102917630803806e-06\n",
      "377 turn:  7.672966617420384e-06\n",
      "378 turn:  7.2657679530680905e-06\n",
      "379 turn:  6.88024627779282e-06\n",
      "380 turn:  6.5153873400887205e-06\n",
      "381 turn:  6.169790960273831e-06\n",
      "382 turn:  5.842569512392633e-06\n",
      "383 turn:  5.532772935527289e-06\n",
      "384 turn:  5.2393611464890654e-06\n",
      "385 turn:  4.961695585082774e-06\n",
      "386 turn:  4.698666050029711e-06\n",
      "387 turn:  4.449615408169093e-06\n",
      "388 turn:  4.213753712458957e-06\n",
      "389 turn:  3.9904277976179e-06\n",
      "390 turn:  3.7790247354853645e-06\n",
      "391 turn:  3.5787928135964137e-06\n",
      "392 turn:  3.3892063631598012e-06\n",
      "393 turn:  3.2096362132788383e-06\n",
      "394 turn:  3.0396530288488195e-06\n",
      "395 turn:  2.8786685284919964e-06\n",
      "396 turn:  2.726202126414929e-06\n",
      "397 turn:  2.5818751525087236e-06\n",
      "398 turn:  2.4451477351870475e-06\n",
      "399 turn:  2.31573043573318e-06\n",
      "400 turn:  2.1931173548072367e-06\n",
      "401 turn:  2.0770295654097676e-06\n",
      "402 turn:  1.967128023096259e-06\n",
      "403 turn:  1.8630412735488688e-06\n",
      "404 turn:  1.764463165814683e-06\n",
      "405 turn:  1.6710855592029197e-06\n",
      "406 turn:  1.5826716768673934e-06\n",
      "407 turn:  1.4989239296002745e-06\n",
      "408 turn:  1.4196754207078823e-06\n",
      "409 turn:  1.3445659072072176e-06\n",
      "410 turn:  1.2734526315309355e-06\n",
      "411 turn:  1.2060913996847317e-06\n",
      "412 turn:  1.1423173523661237e-06\n",
      "413 turn:  1.081920046736032e-06\n",
      "414 turn:  1.0247212461277875e-06\n",
      "415 turn:  9.705379693601125e-07\n",
      "416 turn:  9.192259989898466e-07\n",
      "417 turn:  8.706424469041672e-07\n",
      "418 turn:  8.246218524442891e-07\n",
      "419 turn:  7.81040048504483e-07\n",
      "420 turn:  7.397697391949295e-07\n",
      "421 turn:  7.006788086232278e-07\n",
      "422 turn:  6.63660286421615e-07\n",
      "423 turn:  6.28592940983484e-07\n",
      "424 turn:  5.9537861791525e-07\n",
      "425 turn:  5.639300114068423e-07\n",
      "426 turn:  5.341416110983703e-07\n",
      "427 turn:  5.059279641380769e-07\n",
      "428 turn:  4.792035002605719e-07\n",
      "429 turn:  4.538910136591621e-07\n",
      "430 turn:  4.299210062744016e-07\n",
      "431 turn:  4.072234216749792e-07\n",
      "432 turn:  3.8572038774953873e-07\n",
      "433 turn:  3.653506256591225e-07\n",
      "434 turn:  3.460608828517082e-07\n",
      "435 turn:  3.2778866288894654e-07\n",
      "436 turn:  3.1049152951253663e-07\n",
      "437 turn:  2.9409909124065355e-07\n",
      "438 turn:  2.785787014789555e-07\n",
      "439 turn:  2.6387324866881316e-07\n",
      "440 turn:  2.4994869660446724e-07\n",
      "441 turn:  2.367592876629368e-07\n",
      "442 turn:  2.242656869666005e-07\n",
      "443 turn:  2.1243093394464778e-07\n",
      "444 turn:  2.0121997937206645e-07\n",
      "445 turn:  1.906060338530331e-07\n",
      "446 turn:  1.8054847961415881e-07\n",
      "447 turn:  1.7102398491841443e-07\n",
      "448 turn:  1.620019033962644e-07\n",
      "449 turn:  1.5345564152705192e-07\n",
      "450 turn:  1.4536301071424392e-07\n",
      "451 turn:  1.376945601679692e-07\n",
      "452 turn:  1.3043210036805967e-07\n",
      "453 turn:  1.23553469646272e-07\n",
      "454 turn:  1.1703800258889685e-07\n",
      "455 turn:  1.1086830792404084e-07\n",
      "456 turn:  1.0502178576557481e-07\n",
      "457 turn:  9.948406778537476e-08\n",
      "458 turn:  9.423862553689013e-08\n",
      "459 turn:  8.927124623895969e-08\n",
      "460 turn:  8.456513574634718e-08\n",
      "461 turn:  8.010638077657792e-08\n",
      "462 turn:  7.588336534223352e-08\n",
      "463 turn:  7.188298002446148e-08\n",
      "464 turn:  6.809505433059679e-08\n",
      "465 turn:  6.450624766230859e-08\n",
      "466 turn:  6.110596316920782e-08\n",
      "467 turn:  5.788514096792775e-08\n",
      "468 turn:  5.483453412040916e-08\n",
      "469 turn:  5.194532054647214e-08\n",
      "470 turn:  4.920832643887951e-08\n",
      "471 turn:  4.661524175967494e-08\n",
      "472 turn:  4.4159096302092053e-08\n",
      "473 turn:  4.1832701227714043e-08\n",
      "474 turn:  3.962903772256141e-08\n",
      "475 turn:  3.7541201111253436e-08\n",
      "476 turn:  3.556356409675227e-08\n",
      "477 turn:  3.368996642293717e-08\n",
      "478 turn:  3.1915337014913984e-08\n",
      "479 turn:  3.0234311151580345e-08\n",
      "480 turn:  2.8641674267199833e-08\n",
      "481 turn:  2.7133124655721982e-08\n",
      "482 turn:  2.570393119686377e-08\n",
      "483 turn:  2.4350411295678673e-08\n",
      "484 turn:  2.3068005376201852e-08\n",
      "485 turn:  2.1853041727917374e-08\n",
      "486 turn:  2.0702234485637957e-08\n",
      "487 turn:  1.961214318486205e-08\n",
      "488 turn:  1.857957745417731e-08\n",
      "489 turn:  1.7601418205578073e-08\n",
      "490 turn:  1.667468058392773e-08\n",
      "491 turn:  1.579663678380249e-08\n",
      "492 turn:  1.4964991934925337e-08\n",
      "493 turn:  1.4177399091356287e-08\n",
      "494 turn:  1.3430992967113258e-08\n",
      "495 turn:  1.2723857144078214e-08\n",
      "496 turn:  1.2053976522048493e-08\n",
      "497 turn:  1.1419434951516932e-08\n",
      "498 turn:  1.0818572194702817e-08\n",
      "499 turn:  1.0249059302071706e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "N,D_in,H,D_out = 54,1000,100,10\n",
    "\n",
    "# 创建随机输入和输出\n",
    "x = np.random.randn(N , D_in)\n",
    "y = np.random.randn(N , D_out)\n",
    "\n",
    "# 随机初始化权值\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    # forward 前向过程\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t,\"turn: \", loss)\n",
    "    \n",
    "    # backprop 后向过程\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来看tensor是怎么解决这个问题的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# TO-DO\n",
    "import torch\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "print(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到numpy.ndarray和torch.tensor是非常相似的。\n",
    "\n",
    "* 构造一个 $ 5 \\times 3 $ 的0矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.8946e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 1.1692e-19, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 随机初始化两个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3405, 0.6669, 0.4768],\n",
      "        [0.1587, 0.8933, 0.8746],\n",
      "        [0.4759, 0.2391, 0.2873],\n",
      "        [0.7888, 0.8154, 0.0488],\n",
      "        [0.9692, 0.3559, 0.4046]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 获取`size()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6669, 0.8933, 0.2391, 0.8154, 0.3559])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构造全0张量并且转换为numpy格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "<class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，`tensor.numpy()`是一个浅拷贝，换言之，使用这种转换的时候是一个引用.\n",
    "继续看下面的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将`numpy.ndarray`转换为`torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "np.add(a , 1 ,out = a)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最后查看一下如何转化为GPU运行（一般只需要全局设计一下即可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. automatic differentiation engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 的关键在于自动求导Autograd技术，这个具体的操作请查看evernote笔记\n",
    "我们直接来看这个操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
