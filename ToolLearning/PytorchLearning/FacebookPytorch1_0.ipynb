{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Facebook Pytorch 1.0 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?\n",
    "**PyTorch的组成部分：**\n",
    "1. automatic differentiation engine\n",
    "2. Ndarray library with GPU support\n",
    "3. Distributed training\n",
    "4. Production-ready C++ runtime\n",
    "5. gradient based optimization package\n",
    "6. Utilities(data loading,etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ndarray library\n",
    "Pytorch被称为神经网络的numpy，为什么呢？因为`np.ndarry` <-> `torch.Tensor`中的操作非常相似，加上GPU，所以运算非常快，下面我们比较一下：\n",
    "\n",
    "* 首先是numpy 代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 turn:  25902431.879741177\n1 turn:  19667915.881960966\n2 turn:  15703056.330939017\n3 turn:  12327716.761904921\n4 turn:  9261643.786908623\n5 turn:  6650974.979294437\n6 turn:  4634447.263955887\n7 turn:  3192417.3091512616\n8 turn:  2215607.1908576544\n9 turn:  1570944.481600485\n10 turn:  1145688.8724153633\n11 turn:  862917.4575967597\n12 turn:  669830.348605209\n13 turn:  533807.5029864854\n14 turn:  434891.61297826376\n15 turn:  360650.2440819749\n16 turn:  303279.8470286433\n17 turn:  257781.675638947\n18 turn:  220997.61671311493\n19 turn:  190788.10689599218\n20 turn:  165636.85301751236\n21 turn:  144447.24898729956\n22 turn:  126464.36986866029\n23 turn:  111101.4644300804\n24 turn:  97903.51607467321\n25 turn:  86501.50336650021\n26 turn:  76614.88797254513\n27 turn:  68004.53541816722\n28 turn:  60481.781052643564\n29 turn:  53888.58197762249\n30 turn:  48100.6526167174\n31 turn:  43004.21008457731\n32 turn:  38502.26470520457\n33 turn:  34520.42071436035\n34 turn:  30992.228937691594\n35 turn:  27861.528989045695\n36 turn:  25080.636169774876\n37 turn:  22607.38394269219\n38 turn:  20406.568710251217\n39 turn:  18440.344891200773\n40 turn:  16683.70361585092\n41 turn:  15110.01156784856\n42 turn:  13699.98752295794\n43 turn:  12433.35268130574\n44 turn:  11293.382872256041\n45 turn:  10266.112457910207\n46 turn:  9338.973879103713\n47 turn:  8501.72568331862\n48 turn:  7745.065862976546\n49 turn:  7060.626866854718\n50 turn:  6441.55970336961\n51 turn:  5880.398153990335\n52 turn:  5371.174959784472\n53 turn:  4908.875786508029\n54 turn:  4488.900446187956\n55 turn:  4106.900699463187\n56 turn:  3759.2504637554384\n57 turn:  3442.861078294462\n58 turn:  3154.5467729098827\n59 turn:  2891.7460316597308\n60 turn:  2651.987245699856\n61 turn:  2433.1756109341422\n62 turn:  2233.3990010470934\n63 turn:  2050.84325768622\n64 turn:  1883.9450616784104\n65 turn:  1731.5018562782375\n66 turn:  1591.9545981923427\n67 turn:  1464.280987651638\n68 turn:  1347.3376683203628\n69 turn:  1240.1466345046583\n70 turn:  1141.9615494433633\n71 turn:  1051.9052402292507\n72 turn:  969.2431431058246\n73 turn:  893.3578663995013\n74 turn:  823.6774979340476\n75 turn:  759.6874849061501\n76 turn:  700.9437586249365\n77 turn:  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646.9065655999876\n78 turn:  597.2102554244776\n79 turn:  551.4949372286114\n80 turn:  509.43816786447627\n81 turn:  470.72208427066596\n82 turn:  435.08496201494575\n83 turn:  402.26805141435295\n84 turn:  372.0138251592045\n85 turn:  344.124383895698\n86 turn:  318.41523612349715\n87 turn:  294.71431845797423\n88 turn:  272.8390813070329\n89 turn:  252.65103823189216\n90 turn:  234.01506179948947\n91 turn:  216.8087551164233\n92 turn:  200.9244261267948\n93 turn:  186.25221741727066\n94 turn:  172.68760621635136\n95 turn:  160.15031280140974\n96 turn:  148.56054005894765\n97 turn:  137.8372175992073\n98 turn:  127.91991325859985\n99 turn:  118.75138800348756\n100 turn:  110.26487474124909\n101 turn:  102.41039768764666\n102 turn:  95.1333265255108\n103 turn:  88.39346526737651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 turn:  82.15044613473059\n105 turn:  76.36425084544203\n106 turn:  70.99933464423403\n107 turn:  66.02571442281021\n108 turn:  61.414244476108024\n109 turn:  57.13907851868351\n110 turn:  53.171494445953726\n111"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " turn:  49.488627371120366\n112 turn:  46.069920157606646\n113 turn:  42.89515486747504\n114 turn:  39.94756853571388\n115 turn:  37.20978180900774\n116 turn:  34.66745046500081\n117 turn:  32.30360732980086\n118 turn:  30.107300971386387\n119 turn:  28.065622663412583\n120 turn:  26.167292335773162\n121 turn:  24.402515659890298\n122 turn:  22.762056006581915\n123 turn:  21.23401209293017\n124 turn:  19.812268254217525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 turn:  18.48901937523243\n126 turn:  17.257567573709732\n127 turn:  16.11117562819771\n128 turn:  15.043502591390881\n129 turn:  14.04868752991913\n130 turn:  13.12194477495441\n131 turn:  12.258587995268186\n132 turn:  11.453983009205043\n133 turn:  10.70432784966357\n134 turn:  10.005809973393832\n135 turn:  9.353662130801748\n136 turn:  8.745497939650331\n137 turn:  8.178370554828074\n138 turn:  7.649167636163728\n139 turn:  7.155592945780702\n140 turn:  6.694686495495442\n141 turn:  6.2644647309643915\n142 turn:  5.862864648807858\n143 turn:  5.4878020372902085\n144 turn:  5.137555907235001\n145 turn:  4.810568565660715\n146 turn:  4.505044509274221\n147 turn:  4.219514133614725\n148 turn:  3.9525850952351815\n149 turn:  3.703065383916044\n150 turn:  3.4699032882551144\n151 turn:  3.2518666689491784\n152 turn:  3.0479213403836214\n153 turn:  2.8571417611194967\n154 turn:  2.678658947873913\n155 turn:  2.511679391008706\n156 turn:  2.35553283532696\n157 turn:  2.2094521153289444\n158 turn:  2.0725620396257836\n159 turn:  1.9444029945137216\n160 turn:  1.8244079891411593\n161 turn:  1.7120592528263507\n162 turn:  1.6069296648150575\n163 turn:  1.5083395742769032\n164 turn:  1.4159785010556503\n165 turn:  1.3294342454714005\n166 turn:  1.2483428249630504\n167 turn:  1.172424638579899\n168 turn:  1.1012019991759614\n169 turn:  1.034396508908697\n170 turn:  0.9717564256100037\n171 turn:  0.9130222221123119\n172 turn:  0.8579339854299484\n173 turn:  0.8062727666364026\n174 turn:  0.757804929223045\n175 turn:  0.7123153273934077\n176 turn:  0.6696600888607904\n177 turn:  0.6296216392646574\n178 turn:  0.5920163463611552\n179 turn:  0.5567356518937989\n180 turn:  0.5236008982530804\n181 turn:  0.4924854888656713\n182 turn:  0.4632609879216851\n183 turn:  0.4358143215374189\n184 turn:  0.41003601112072674\n185 turn:  0.38584848386519066\n186 turn:  0.36310468536678586\n187 turn:  0.34172984085223\n188 turn:  0.3216382161887748\n189 turn:  0.3027583748437487\n190 turn:  0.28501398821206714\n191 turn:  0.26833768911200706\n192 turn:  0.252651804989108\n193 turn:  0.2379048499075533\n194 turn:  0.22405022245685866\n195 turn:  0.21101014050186523\n196 turn:  0.1987464976312059\n197 turn:  0.18721193409351317\n198 turn:  0.17636020155164855\n199 turn:  0.1661482667851628\n200 turn:  0.15654018859577365\n201 turn:  0.14749938520248626\n202 turn:  0.13900130034181526\n203 turn:  0.130997223671877\n204 turn:  0.12345952804044019\n205 turn:  0.11636412680784693\n206 turn:  0.10968541619119918\n207 turn:  0.10339767249091192\n208 turn:  0.09747951614735645\n209 turn:  0.0919041294790966\n210 turn:  0.08665704875606159\n211 turn:  0.08171259781377452\n212 turn:  0.07705479249095987\n213 turn:  0.072667419446792\n214 turn:  0.06853540389403022\n215 turn:  0.06464186770082037\n216 turn:  0.06097237026898573\n217 turn:  0.05751628843856565\n218 turn:  0.054259090067460214\n219 turn:  0.05119076041825609\n220 turn:  0.04829773859702166\n221 turn:  0.04556982206811883\n222 turn:  0.04299844193236374\n223 turn:  0.04057494224056757\n224 turn:  0.038290958515066725\n225"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " turn:  0.03613783222419072\n226 turn:  0.034106639194329956\n227 turn:  0.03219130338800727\n228 turn:  0.03038517778430556\n229 turn:  0.028681588807520943\n230 turn:  0.027074947610945345\n231 turn:  0.025561666174693944\n232 turn:  0.024132491931736076\n233 turn:  0.02278405652966845\n234 turn:  0.021511990869381888\n235 turn:  0.020312006192290937\n236 turn:  0.01918024365458272\n237 turn:  0.018112754958608757\n238 turn:  0.017104968884360652\n239 turn:  0.01615375179708508\n240 turn:  0.01525632833756257\n241 turn:  0.014409156008280471\n242 turn:  0.013609815964507128\n243 turn:  0.012855567552176672\n244 turn:  0.0121437109394431\n245 turn:  0.011471336100578575\n246 turn:  0.010836611541906033\n247 turn:  0.010237433991086873\n248 turn:  0.009672211056378603\n249 turn:  0.00913836268610371\n250 turn:  0.008634246914576304\n251 turn:  0.0081581151190163\n252 turn:  0.007708590885434447\n253 turn:  0.00728405749317642\n254 turn:  0.006883270375649825\n255 turn:  0.006504794654337492\n256 turn:  0.006147252968907987\n257 turn:  0.005809523457590225\n258 turn:  0.005490500267785075\n259 turn:  0.005189199255967822\n260 turn:  0.004904753030793321\n261 turn:  0.004636016196476907\n262 turn:  0.004381998131270914\n263 turn:  0.004142030919839877\n264 turn:  0.003915342838853349\n265 turn:  0.0037012529469110577\n266 turn:  0.003499052256316873\n267 turn:  0.0033078394183046755\n268 turn:  0.003127170569051255\n269 turn:  0.002956496261452622\n270 turn:  0.002795183142704859\n271 turn:  0.0026428662551118195\n272 turn:  0.0024988229153926978\n273 turn:  0.002362699303174137\n274 turn:  0.0022340415339139465\n275 turn:  0.002112449520938235\n276 turn:  0.0019975684682335204\n277 turn:  0.0018889930158931282\n278 turn:  0.0017863044904586722\n279 turn:  0.0016892336035304524\n280 turn:  0.0015974867502590402\n281 turn:  0.0015108069771379213\n282 turn:  0.001428827545581348\n283 turn:  0.001351339675457398\n284 turn:  0.0012780579333945643\n285 turn:  0.0012088047938374055\n286 turn:  0.001143335549961839\n287 turn:  0.0010814067622037936\n288 turn:  0.0010228646146218786\n289 turn:  0.0009675192488090246\n290 turn:  0.000915215143672977\n291 turn:  0.000865720984770422\n292 turn:  0.0008189165607682355\n293 turn:  0.0007746583602369848\n294 turn:  0.0007328424411083482\n295 turn:  0.0006932763052105065\n296 turn:  0.0006558472636059953\n297 turn:  0.0006204512511477156\n298 turn:  0.0005869925224476539\n299 turn:  0.0005553535451659805\n300 turn:  0.0005254213710987915\n301 turn:  0.00049710092542193\n302 turn:  0.0004703223845211501\n303 turn:  0.00044500188425022826\n304 turn:  0.0004210385444394743\n305 turn:  0.0003983756644628934\n306 turn:  0.0003769444198647775\n307 turn:  0.0003566779027766775\n308 turn:  0.0003374935999901309\n309 turn:  0.00031934659161121377\n310 turn:  0.0003021825726337542\n311 turn:  0.0002859585793087375\n312 turn:  0.00027059769912988\n313 turn:  0.00025606412736542167\n314 turn:  0.00024231518892271252\n315 turn:  0.0002293158913187318\n316 turn:  0.00021700945501176646\n317 turn:  0.00020536971441990456\n318 turn:  0.00019435555108204372\n319 turn:  0.00018393800368825516\n320 turn:  0.0001740776594504881\n321 turn:  0.0001647481466005371\n322 turn:  0.0001559245861539491\n323 turn:  0.00014757540529492565\n324 turn:  0.00013967246192801074\n325 turn:  0.00013219316662492912\n326 turn:  0.0001251189475947562\n327 turn:  0.00011842212435009325\n328 turn:  0.00011208790975538055\n329 turn:  0.00010609345644226235\n330 turn:  0.00010042022278421576\n331 turn:  9.504989817085725e-05\n332 turn:  8.99690598654437e-05\n333 turn:  8.516212790474584e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 turn:  8.061175915059923e-05\n335 turn:  7.630478851167481e-05\n336 turn:  7.222998583053305e-05\n337 turn:  6.837333738253106e-05\n338 turn:  6.472206563795398e-05\n339 turn:  6.126706406838408e-05\n340 turn:  5.799840992027617e-05\n341 turn:  5.490385132341202e-05\n342 turn:  5.1974346769910984e-05\n343 turn:  4.9203306370805166e-05\n344 turn:  4.657871977932011e-05\n345 turn:  4.409529028559907e-05\n346 turn:  4.1745624660792006e-05\n347 turn:  3.952013064859082e-05\n348 turn:  3.741356884119265e-05\n349 turn:  3.542060156858078e-05\n350 turn:  3.3533779546417576e-05\n351 turn:  3.174752076868103e-05\n352 turn:  3.005717396162182e-05\n353 turn:  2.8456440277215083e-05\n354 turn:  2.694151207641914e-05\n355 turn:  2.5507608710717385e-05\n356 turn:  2.4149800209581932e-05\n357 turn:  2.2864786125790542e-05\n358 turn:  2.1648662869251148e-05\n359 turn:  2.0496921600090074e-05\n360 turn:  1.940650390396995e-05\n361 turn:  1.8374549444551858e-05\n362 turn:  1.7397406651527572e-05\n363 turn:  1.6472867115506033e-05\n364 turn:  1.5597395823464107e-05\n365 turn:  1.4768212929909971e-05\n366 turn:  1.3983321497920394e-05\n367 turn:  1.3240439398183686e-05\n368 turn:  1.2537063793805674e-05\n369 turn:  1.1871165297909287e-05\n370 turn:  1.124055623128511e-05\n371 turn:  1.0643502132343109e-05\n372 turn:  1.0078544497745544e-05\n373 turn:  9.54331170901352e-06\n374 turn:  9.03675209901408e-06\n375 turn:  8.557081994572229e-06\n376 turn:  8.102917630803806e-06\n377 turn:  7.672966617420384e-06\n378 turn:  7.2657679530680905e-06\n379 turn:  6.88024627779282e-06\n380 turn:  6.5153873400887205e-06\n381 turn:  6.169790960273831e-06\n382 turn:  5.842569512392633e-06\n383 turn:  5.532772935527289e-06\n384 turn:  5.2393611464890654e-06\n385 turn:  4.961695585082774e-06\n386 turn:  4.698666050029711e-06\n387 turn:  4.449615408169093e-06\n388 turn:  4.213753712458957e-06\n389 turn:  3.9904277976179e-06\n390 turn:  3.7790247354853645e-06\n391 turn:  3.5787928135964137e-06\n392 turn:  3.3892063631598012e-06\n393 turn:  3.2096362132788383e-06\n394 turn:  3.0396530288488195e-06\n395 turn:  2.8786685284919964e-06\n396 turn:  2.726202126414929e-06\n397 turn:  2.5818751525087236e-06\n398 turn:  2.4451477351870475e-06\n399 turn:  2.31573043573318e-06\n400 turn:  2.1931173548072367e-06\n401 turn:  2.0770295654097676e-06\n402 turn:  1.967128023096259e-06\n403 turn:  1.8630412735488688e-06\n404 turn:  1.764463165814683e-06\n405 turn:  1.6710855592029197e-06\n406 turn:  1.5826716768673934e-06\n407 turn:  1.4989239296002745e-06\n408 turn:  1.4196754207078823e-06\n409 turn:  1.3445659072072176e-06\n410 turn:  1.2734526315309355e-06\n411 turn:  1.2060913996847317e-06\n412 turn:  1.1423173523661237e-06\n413 turn:  1.081920046736032e-06\n414 turn:  1.0247212461277875e-06\n415 turn:  9.705379693601125e-07\n416 turn:  9.192259989898466e-07\n417 turn:  8.706424469041672e-07\n418 turn:  8.246218524442891e-07\n419 turn:  7.81040048504483e-07\n420 turn:  7.397697391949295e-07\n421 turn:  7.006788086232278e-07\n422 turn:  6.63660286421615e-07\n423 turn:  6.28592940983484e-07\n424 turn:  5.9537861791525e-07\n425 turn:  5.639300114068423e-07\n426 turn:  5.341416110983703e-07\n427 turn:  5.059279641380769e-07\n428 turn:  4.792035002605719e-07\n429 turn:  4.538910136591621e-07\n430 turn:  4.299210062744016e-07\n431 turn:  4.072234216749792e-07\n432 turn:  3.8572038774953873e-07\n433 turn:  3.653506256591225e-07\n434 turn:  3.460608828517082e-07\n435 turn:  3.2778866288894654e-07\n436 turn:  3.1049152951253663e-07\n437 turn:  2.9409909124065355e-07\n438 turn:  2.785787014789555e-07\n439 turn:  2.6387324866881316e-07\n440"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " turn:  2.4994869660446724e-07\n441 turn:  2.367592876629368e-07\n442 turn:  2.242656869666005e-07\n443 turn:  2.1243093394464778e-07\n444 turn:  2.0121997937206645e-07\n445 turn:  1.906060338530331e-07\n446 turn:  1.8054847961415881e-07\n447 turn:  1.7102398491841443e-07\n448 turn:  1.620019033962644e-07\n449 turn:  1.5345564152705192e-07\n450 turn:  1.4536301071424392e-07\n451 turn:  1.376945601679692e-07\n452 turn:  1.3043210036805967e-07\n453 turn:  1.23553469646272e-07\n454 turn:  1.1703800258889685e-07\n455 turn:  1.1086830792404084e-07\n456 turn:  1.0502178576557481e-07\n457 turn:  9.948406778537476e-08\n458 turn:  9.423862553689013e-08\n459 turn:  8.927124623895969e-08\n460 turn:  8.456513574634718e-08\n461 turn:  8.010638077657792e-08\n462 turn:  7.588336534223352e-08\n463 turn:  7.188298002446148e-08\n464 turn:  6.809505433059679e-08\n465 turn:  6.450624766230859e-08\n466 turn:  6.110596316920782e-08\n467 turn:  5.788514096792775e-08\n468 turn:  5.483453412040916e-08\n469 turn:  5.194532054647214e-08\n470 turn:  4.920832643887951e-08\n471 turn:  4.661524175967494e-08\n472 turn:  4.4159096302092053e-08\n473 turn:  4.1832701227714043e-08\n474 turn:  3.962903772256141e-08\n475 turn:  3.7541201111253436e-08\n476 turn:  3.556356409675227e-08\n477 turn:  3.368996642293717e-08\n478 turn:  3.1915337014913984e-08\n479 turn:  3.0234311151580345e-08\n480 turn:  2.8641674267199833e-08\n481 turn:  2.7133124655721982e-08\n482 turn:  2.570393119686377e-08\n483 turn:  2.4350411295678673e-08\n484 turn:  2.3068005376201852e-08\n485 turn:  2.1853041727917374e-08\n486 turn:  2.0702234485637957e-08\n487 turn:  1.961214318486205e-08\n488 turn:  1.857957745417731e-08\n489 turn:  1.7601418205578073e-08\n490 turn:  1.667468058392773e-08\n491 turn:  1.579663678380249e-08\n492 turn:  1.4964991934925337e-08\n493 turn:  1.4177399091356287e-08\n494 turn:  1.3430992967113258e-08\n495 turn:  1.2723857144078214e-08\n496 turn:  1.2053976522048493e-08\n497 turn:  1.1419434951516932e-08\n498 turn:  1.0818572194702817e-08\n499 turn:  1.0249059302071706e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "N,D_in,H,D_out = 54,1000,100,10\n",
    "\n",
    "# 创建随机输入和输出\n",
    "x = np.random.randn(N , D_in)\n",
    "y = np.random.randn(N , D_out)\n",
    "\n",
    "# 随机初始化权值\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    # forward 前向过程\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t,\"turn: \", loss)\n",
    "    \n",
    "    # backprop 后向过程\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来看tensor是怎么解决这个问题的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# TO-DO\n",
    "import torch\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "print(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到numpy.ndarray和torch.tensor是非常相似的。\n",
    "\n",
    "* 构造一个 $ 5 \\times 3 $ 的0矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 1.8946e-42, 0.0000e+00],\n        [0.0000e+00, 1.1692e-19, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 随机初始化两个矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3405, 0.6669, 0.4768],\n        [0.1587, 0.8933, 0.8746],\n        [0.4759, 0.2391, 0.2873],\n        [0.7888, 0.8154, 0.0488],\n        [0.9692, 0.3559, 0.4046]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 获取`size()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 切片操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6669, 0.8933, 0.2391, 0.8154, 0.3559])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构造全0张量并且转换为numpy格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n<class 'torch.Tensor'>\n[1. 1. 1. 1. 1.]\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，`tensor.numpy()`是一个浅拷贝，换言之，使用这种转换的时候是一个引用.\n",
    "继续看下面的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 将`numpy.ndarray`转换为`torch.tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\ntensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "np.add(a , 1 ,out = a)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最后查看一下如何转化为GPU运行（一般只需要全局设计一下即可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. automatic differentiation engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 的关键在于自动求导Autograd技术，这个具体的操作请查看evernote笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
